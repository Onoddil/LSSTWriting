% mnras_template.tex
%
% LaTeX template for creating an MNRAS paper
%
% v3.0 released 14 May 2015
% (version numbers match those of mnras.cls)
%
% Copyright (C) Royal Astronomical Society 2015
% Authors:
% Keith T. Smith (Royal Astronomical Society)

% Change log
%
% v3.0 May 2015
%    Renamed to match the new package name
%    Version number matches mnras.cls
%    A few minor tweaks to wording
% v1.0 September 2013
%    Beta testing only - never publicly released
%    First version: a simple (ish) template for creating an MNRAS paper

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Basic setup. Most papers should leave these options alone.
\documentclass[fleqn,usenatbib]{mnras}

% MNRAS is set in Times font. If you don't have this installed (most LaTeX
% installations will be fine) or prefer the old Computer Modern fonts, comment
% out the following line
\usepackage{newtxtext,newtxmath}
% Depending on your LaTeX fonts installation, you might get better results with one of these:
%\usepackage{mathptmx}
%\usepackage{txfonts}

% Use vector fonts, so it zooms properly in on-screen viewing software
% Don't change these lines unless you know what you are doing
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}


%%%%% AUTHORS - PLACE YOUR OWN PACKAGES HERE %%%%%
\usepackage{bm}
\usepackage[usenames, dvipsnames]{color}
\usepackage{subcaption}
\captionsetup{compatibility=false}
% Only include extra packages if you really need them. Common packages are:
\usepackage{graphicx}	% Including figure files
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}	% Extra maths symbols

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% AUTHORS - PLACE YOUR OWN COMMANDS HERE %%%%%
\graphicspath{{./Plots/}}
% Please keep new commands to a minimum, and use \newcommand not \def to avoid
% overwriting existing commands. Example:
%\newcommand{\pcm}{\,cm$^{-2}$}	% per cm-squared

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% TITLE PAGE %%%%%%%%%%%%%%%%%%%

% Title of the paper, and the short title which is used in the headers.
% Keep the title short and informative.
\title[]{Report Jan 2020 â€“ Attempts at parameterising an empirical AUF}

% The list of authors, and the short list which is used in the headers.
% If you need two or more lines of authors, add an extra line using \newauthor
\author[Tom J. Wilson and Tim Naylor]{
Tom J. Wilson
and Tim Naylor
\\
}

% These dates will be filled out by the publisher
\date{}

% Enter the current year, for the copyright statements etc.
\pubyear{2020}

% Don't change these lines
\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Given the depths that LSST will reach, we possibly require a different approach than previously undertaken to compute the perturbation component of the Astrometric Uncertainty Function (AUF) for probabilistic photometric catalogue cross-matching. We document here an attempt to derive this AUF -- along with any other non-statistical AUF component, such as proper motions or binary reflex motion -- from the data themselves, creating in-situ AUFs which do not rely on simulation. Conclusions currently suggest this is not a good approach to take, due to the degeneracies of convolution and the unphysicality of the results.

\end{abstract}

% to do so we need both cross-matches (using Gaia to have an essentially one-sided problem) to create AUFs for those sources we detect; and could then consider first moments of randomly placed PSF circles where no star exists -- or residuals, if detected source subtracted images were available -- in data frames to get the AUF of stars below the detection limit of the survey


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The Astrometric Uncertainty Function (AUF) is the probability density function (PDF) describing the probability of a source being detected at some position given its true location. The probability of two sources being the same intrinsic object detected twice given their respective locations -- or the distance between their given positions -- is the convolution of their respective AUFs. Each AUF is, itself, a convolution of the individual components describing its offset from its ``true'' location. The first of these, and typically the only component used, is its statistical component, in which Poisson noise in a photometric image causes imperfect centroiding of a source.

A second critical component in crowded regions, or in photometric surveys which probe significant depths relative to the length scale of the survey PSF (to which LSST and \textit{WISE} are both subject), is the perturbation from blended sources. These objects, while hidden beneath the flux from a brighter source, contaminant the central object by both adding additional flux, and by tugging on the center-of-light of the composite object. Thus, in this simple two-component model, the AUF is

\begin{equation}
h(\textbf{x}) = (f_\mathrm{stat} * f_\mathrm{blend})(\textbf{x})
\end{equation}
where the notation $(f * g)(x)$ denotes a convolution.

Previously, \citet{2018MNRAS.481.2148W} produced $f_\mathrm{blend}$ by a Monte Carlo simulation, via Galactic stellar densities from a \textsc{trilegal} simulation \citep{Girardi2005}. However, the limiting magnitude of these simulations -- via the public API -- is 32nd magnitude; this was fine for \textit{WISE} where we still had access to stars 10 magnitudes fainter than the limit of the survey (necessary for probing the faintest flux ratios and sufficiently small flux weighted astrometric perturbations), being brighter than $W1=32$. However, the limiting magnitude of LSST is about 27th magnitude, and thus the magnitude limit is out of the range of the \textsc{trilegal} simulations.

\section{In situ AUF}
Thus the need for deriving empirical AUFs was born. Instead of modelling the perturbations from each component individually -- simulating blended source position shifts, unknown proper motions, etc. -- we could extract from the data themselves the AUF describing \textit{all} components, minus the statistical noise component, and use the data-driven AUF subsequently.

The idea here was that we can reverse the equation above, and compute $f_\mathrm{blend}$ directly from knowing the presciption for the statistical AUF and the total PDF describing the probability of two detections being the same source detected twice given their separation. To this end we matched the \textit{WISE} data, thought to be well understood and accurately described by its quoted uncertainties, to \textit{Gaia} data, using the high precision on the \textit{Gaia} dataset to effectively reduce the convolution of the two datasets to that of just the \textit{WISE} data (see \citealt{2017MNRAS.468.2517W}, e.g.), allowing for a one-sided probe of the test.

We are therefore looking for the deconvolution of $f_\mathrm{stat}$ and $f_\mathrm{deblend}$, for which we can turn to Fourier transforms. Where $F = \mathcal{F}[f(x)](\rho)$ denotes the Fourier transform of $f$, we have

\begin{equation}
	h = f * g
\end{equation}
and, if we take the Fourier transform,

\begin{equation}
H = F \times G
\end{equation}
where in Fourier space the convolution is described by a simple multiplication. Thus we can solve for $G$ -- or $f_\mathrm{blend}$ -- as

\begin{equation}
	G = H / F
\end{equation}
and inverse Fourier transform, giving

\begin{equation}
	f_\mathrm{blend}(\textbf{x}) = \mathcal{F}^{-1}\left[\mathcal{F}[h(\textbf{x})](\rho) / \mathcal{F}[f_\mathrm{stat}(\textbf{x})](\rho)\right](\textbf{x}).
\end{equation}

\subsection{Computing the Fourier Transforms}

To reduce the computational expense of a two-dimensional convolution by simplifying it to a 1D integral, we use the Hankel transform,

\begin{equation}
\mathcal{F}[f(r, \theta)](\rho) = \mathcal{F}[f(r)](\rho) = 2 \pi \int\limits_0^\infty\!r f(r) J_0(2 \pi r \rho)\,\mathrm{d}r
\end{equation}
where we assume circular symmetry (i.e., the Hankel transform, or Fourier-Bessel transform, is a two-dimensional Fourier transform under the assumption of a radially symmetric integral kernel) and $J_0$ is the zeroth order Bessel function of first kind. This is computed via a series of small $\Delta r$ bins with each function evaluated at small $r$ (or $\rho$ for an inverse transform) offsets, for a given $\rho$ (or $r$, for inverse transforms).

There is, however, a small instability in this function computed numerically --- no matter how finely you evaluate the functions, $J_0$, effectively a combination of a $1/\sqrt(x)$ function and a $\cos(x)$ function, cannot be reasonably computed with sufficient precision at high $\rho$ in the Fourier transform. At large $\rho$, the $\cos(x)$ component of $J_0$ becomes very rapid, cyling completely every $1/r$ steps (remember it is $J_0(2 \pi r \rho)$ and thus goes as $\cos(2 \pi r \rho)$). This numerical instability is acceptable for a \textit{convolution} (being of order $10^{-5}$), as a convolution \textit{multiplies} Fourier tranforms, and thus our large scale Fourier transform values, which should be effectively zero, are truncated at $10^{-10}$, and thus do not contribute much when inverse Fourier transformed. Unfortunately, for a \textit{deconvolution}, the functions are \textit{divided}, resulting in an inverse Fourier transform which, for large $\rho$, has a constant \textit{but significant} value -- tending to of order unity. We therefore cannot compute the deconvolution numerically.

\subsection{Mixture of Gaussian Model}
Instead of attempting the deconvolution head-on, however, we can sidestep the issue of fourier transform stability altogether. The convolution of two Gaussian functions is analytically known -- the new variance is simply the sum of the variances of the original two functions. Thus, if we were able to describe the total AUF as a sum of $N$ Gaussians, we could trivially remove the statistical noise component of the AUF. To do so we fit a Mixture of Gaussian model (MoG),

\begin{equation}
	f(x) = \sum\limits_i \frac{a_i}{2 \pi \sigma_i^2} \exp{\left(-\frac{1}{2}\frac{x^2}{\sigma_i^2}\right)}
\end{equation}
where $\sum_i a_i = 1$ to ensure proper normalisation. We fit this via the \textsc{scipy} package module \textsc{basinhopping} (and \textsc{minimize}), although as we fit to the separation \textit{counts} we fit a Rayleigh distribution, as opposed to a Gaussian distribution, and thus fit

\begin{equation}
	f(x) = \sum\limits_i \frac{a_i x}{\sigma_i^2} \exp{\left(-\frac{1}{2}\frac{x^2}{\sigma_i^2}\right)}
\end{equation}
again assuming circular symmetry. We also limited all $\sigma_i > \sigma_\mathrm{stat}$ to ensure a non-imaginary uncertainty in the deconvolution AUF, computed as $\sigma_{\mathrm{blend}, i} = \sqrt{\sigma_i^2 - \sigma_\mathrm{stat}^2}$, giving

\begin{equation}
	f_\mathrm{blend}(x) = \sum\limits_i \frac{a_i}{\sigma_{2 \pi \mathrm{blend}, i}^2} \exp{\left(-\frac{1}{2}\frac{x^2}{\sigma_{\mathrm{blend}, i}^2}\right)}.
\end{equation}

This process was repeated for steps of one magnitude $9 \leq W1 \leq 17$ (plus $W1=16.5$, as $W1=17$ suffered from potential small-number statistics effects), for small steps in normalising density ($\Delta N=0.01$, fitting total star counts $W1\lesssim15$ to $N z^m$; see \citealt{2018MNRAS.481.2148W} for more details), magnitude ($\Delta W1 \leq 0.1$, except $\Delta W1=0.3$ for $W1=17$), and quoted astrometric uncertainty ($\Delta \sigma \leq 0.01$, except $\Delta \sigma=0.02$ for $W1=17$). All results have $\chi_\nu^2 \leq 2$ (except $W1=11$ where $\chi_\nu^2 = 3.5$) and thus for the most part suggest good fits to the data, an example of which is shown in Figure \ref{fig:w1_9_tot}.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{{w1_9_total_fit}.png}
    \caption{Fit of a Mixture of Gaussian model to \textit{Gaia}-\textit{WISE} nearest neighbour matches for $W1=9$. Red line is MoG model, solid black histogram shows cross-match countrate, and dashed black line is the instrinsic astrometric uncertainty.}
    \label{fig:w1_9_tot}
\end{figure}

However, Figure \ref{fig:w1_9_deconv} shows the resulting deconvolved AUF, with the statistical component removed. Also shown is a Monte Carlo simulation (as per \citealt{2018MNRAS.481.2148W}), with little agreement between the two. We currently cannot explain the physicality of the MoG deconvolved model, as technically there are many $g$ distributions which, when convolved with $f$, can reproduce $h$.

While this \textit{may} be satisfactory, one of the strengths of the original \citet{2017MNRAS.468.2517W} algorithm was its roots in the physical process, and thus we are currently loathed to persue this line of research any further at present. If, in the future, we cannot resolve the magnitude limit issue for LSST images and catalogues we may be forced to adopt an unphysical, but data-driven, model to describe faint crowded regions in LSST data.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{{w1_9_deconvolve}.png}
    \caption{Deconvolution of MoG model to \textit{Gaia}-\textit{WISE} sources for $W1=9$. Solid black histogram is the Monte Carlo simulation distribution of perturbation offsets, with the MoG model deconvolved shown in red.}
    \label{fig:w1_9_deconv}
\end{figure}


\section{AUF Parameter Reduction}
During this process we also attempted to explore the possibility of reducing the number of free parameters for the description of a perturbation AUF. Currently, based on the \textsc{trilegal} simulations, we require knowledge of the Galactic coordinates ($l$ and $b$, e.g.), central source brightness, and normalising density $N$ (used to scale the \textsc{trilegal} simulated star counts). However, where star counts are described as a power law, each step in magnitude results in a factor $z$ increase in \textit{relative} star counts. Thus, perhaps, we could remove $N$ as a factor and instead use $N_\mathrm{eff}$, this ``relative'' density.

To test this, we took the previously computed perturbation AUFs -- whether physical or not, their convolution with a statistical AUF component \textit{does} describe the total AUF of the data well -- and convolved it with the statistical uncertainty of a new set of sources, with magnitude $m+\mathrm{d}m$. Again we forced the width of $\Delta N$, $\Delta m$, and $\Delta\sigma$ to be small. We then re-selected sources based on the mode $\sigma_\mathrm{stat}$ and a new normalising density, a factor $z^{\mathrm{d}m}$ smaller, to give the same resulting $N_\mathrm{eff}$.

While the brightness of the central source is bright, and the power-law distribution of perturbing source counts holds (for most sources, anyway), this distribution is well fit by the new AUF. However, when the central source is fainter, and most perturbing sources are in the turnover of source counts (see Figure 5, \citealt{2018MNRAS.481.2148W}), we overestimate the number of these perturbing objects, and thus have an AUF which is too broad, and a poor fit to the data. Unfortunately, we conclude that -- perhaps obvious with hindsight -- due to the complex nature of stellar brightness counts within the Galaxy, the naive power law approximation of star counts does not hold and thus cannot be used to simplify our parameterisation in this case, just as it could not in previous Monte Carlo simulations of star perturbations.

\section{Conclusions}
We have explored some attempts to move the full perturbation-inclusive AUF to a new regime with LSST, in which we would have a greater ability to use image frame-level information to better capture the effects of blended sources. Unfortunately, preliminary investigations are inconclusive and ongoing, with a MoG fit to the data which does not currently have a physical explanation. If we can explain the effects and fully parameterise the distributions with MoG models, and thus analytically convolve statistical noise separations with further systematic offsets, we can look further to using LSST images -- detected source residuals or ``empty'' sky otherwise -- to characterise the perturbations of sources below the detection limit, extending the data-driven AUF to fainter magnitudes still.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{mnras}
\bibliography{../../../../Dropbox/PostDoc_Exeter/LaTeX/postdoc_papers_jr2}



% Don't change these lines
\bsp	% typesetting comment
\label{lastpage}
\end{document}

% End of mnras_template.tex